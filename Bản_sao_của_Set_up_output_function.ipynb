{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bản sao của Set up output function.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thoadao0301/AI-Project/blob/PhuongNDU/B%E1%BA%A3n_sao_c%E1%BB%A7a_Set_up_output_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkkyNx9rTXj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "062acd51-f1f4-4539-9814-9dd60529a005"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyqe1JuPEmmB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3aJJj4CTdP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebdbd33a-2230-404b-92d2-01f9a3346267"
      },
      "source": [
        "!pip install keras_facenet"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_facenet\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/c5/6fadf919a86c44b87ba9d8134cc83820b8fa8a98f5c68ff676179e052839/keras-facenet-0.3.2.tar.gz\n",
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn->keras_facenet) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn->keras_facenet) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn->keras_facenet) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn->keras_facenet) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn->keras_facenet) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn->keras_facenet) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn->keras_facenet) (1.15.0)\n",
            "Building wheels for collected packages: keras-facenet\n",
            "  Building wheel for keras-facenet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-facenet: filename=keras_facenet-0.3.2-cp37-none-any.whl size=10386 sha256=9390b5229bf569f80ad9a03c4611f1241c70217eea0bdbb2c79034d4f1706c44\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/53/9a/36c4b52fd22faf4f710d5047d874655b85a1b2cf77accfb9bd\n",
            "Successfully built keras-facenet\n",
            "Installing collected packages: mtcnn, keras-facenet\n",
            "Successfully installed keras-facenet-0.3.2 mtcnn-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6L9K-9_TebR"
      },
      "source": [
        "import sys\n",
        "import os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from keras_facenet import FaceNet\n",
        "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnXp9Dadw3u3"
      },
      "source": [
        "# **Training classification**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ2ZWeieKSsQ"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqZEBiVfVTvX"
      },
      "source": [
        "# Gets a detection dict for each face\n",
        "# in an image. Each one has the bounding box and\n",
        "# face landmarks (from mtcnn.MTCNN) along with\n",
        "# the embedding from FaceNet.\n",
        "# return List of embedded images in folder\n",
        "def get_embedding(dir, embedder):\n",
        "    x = []\n",
        "    with tqdm(total=len(os.listdir(dir)), file=sys.stdout) as pbar:\n",
        "      for filename in os.listdir(dir):\n",
        "        # set up file path\n",
        "        filepath = os.path.join(dir,filename) \n",
        "        # load image from file\n",
        "        image = Image.open(filepath)\n",
        "        # convert to RGB, if needed\n",
        "        image = image.convert('RGB')\n",
        "        # convert to array\n",
        "        pixels = np.asarray(image)\n",
        "        # get embeddings for the faces in an image\n",
        "        detections = embedder.extract(pixels, threshold=0.95)\n",
        "        if(len(detections)<1):\n",
        "            print('ERROR: Can\\'t not detect face: ',filepath)\n",
        "            continue\n",
        "        if(len(detections)>1):\n",
        "            print('ERROR: More than two face detected: ', filepath)\n",
        "            continue\n",
        "        x.append(detections[0]['embedding'])\n",
        "        pbar.update(1)\n",
        "    return x\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO4ulbectP33"
      },
      "source": [
        "# Get embedded list images and list labels in folder\n",
        "def load_dataset(dir, embedder):\n",
        "    x , y = [],[]\n",
        "    for subdir in os.listdir(dir):\n",
        "        subdir_path = dir+'/'+subdir\n",
        "        \n",
        "        data_embedding = get_embedding(subdir_path, embedder)\n",
        "        for data in data_embedding:\n",
        "            x.append(data)\n",
        "            y.append(subdir)\n",
        "    return x, y"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STaXGOQgprbU"
      },
      "source": [
        "# Create embedder tools with keras_facenet\n",
        "embedder = FaceNet()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trbPV-P3hrAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da74c17-fca4-4260-d82d-b590960e6f3b"
      },
      "source": [
        "# Create train dataset\n",
        "dataset_train_path= '/content/drive/Shareddrives/AI_Project/DatasetVietNam/DataVietNam/VietNam/VN_Male' # Train data path\n",
        "train_x, train_y = load_dataset(dataset_train_path, embedder)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 144/144 [02:56<00:00,  1.22s/it]\n",
            "100%|██████████| 189/189 [03:33<00:00,  1.13s/it]\n",
            "100%|██████████| 164/164 [02:49<00:00,  1.04s/it]\n",
            "100%|██████████| 143/143 [02:42<00:00,  1.13s/it]\n",
            "100%|██████████| 178/178 [03:20<00:00,  1.12s/it]\n",
            "100%|██████████| 174/174 [04:03<00:00,  1.40s/it]\n",
            "100%|██████████| 207/207 [03:48<00:00,  1.10s/it]\n",
            "100%|██████████| 214/214 [04:13<00:00,  1.19s/it]\n",
            "100%|██████████| 134/134 [03:35<00:00,  1.60s/it]\n",
            "100%|██████████| 203/203 [04:03<00:00,  1.20s/it]\n",
            "100%|██████████| 170/170 [03:11<00:00,  1.13s/it]\n",
            "100%|██████████| 170/170 [04:39<00:00,  1.64s/it]\n",
            "100%|██████████| 208/208 [05:31<00:00,  1.59s/it]\n",
            "100%|██████████| 183/183 [04:22<00:00,  1.44s/it]\n",
            "100%|██████████| 201/201 [04:54<00:00,  1.46s/it]\n",
            "100%|██████████| 174/174 [04:10<00:00,  1.44s/it]\n",
            "100%|██████████| 201/201 [04:15<00:00,  1.27s/it]\n",
            "100%|██████████| 180/180 [04:14<00:00,  1.41s/it]\n",
            "100%|██████████| 177/177 [03:07<00:00,  1.06s/it]\n",
            "100%|██████████| 174/174 [02:47<00:00,  1.04it/s]\n",
            "100%|██████████| 209/209 [04:14<00:00,  1.22s/it]\n",
            "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n",
            "100%|██████████| 144/144 [03:00<00:00,  1.25s/it]\n",
            "100%|██████████| 177/177 [03:42<00:00,  1.26s/it]\n",
            "100%|██████████| 208/208 [05:49<00:00,  1.68s/it]\n",
            "100%|██████████| 172/172 [04:13<00:00,  1.47s/it]\n",
            "100%|██████████| 213/213 [04:43<00:00,  1.33s/it]\n",
            "100%|██████████| 190/190 [05:26<00:00,  1.72s/it]\n",
            "100%|██████████| 193/193 [03:48<00:00,  1.19s/it]\n",
            "100%|██████████| 200/200 [03:21<00:00,  1.01s/it]\n",
            "100%|██████████| 213/213 [04:41<00:00,  1.32s/it]\n",
            "100%|██████████| 163/163 [04:01<00:00,  1.48s/it]\n",
            "100%|██████████| 146/146 [04:12<00:00,  1.73s/it]\n",
            "100%|██████████| 156/156 [03:56<00:00,  1.51s/it]\n",
            "100%|██████████| 142/142 [03:01<00:00,  1.28s/it]\n",
            "100%|██████████| 188/188 [04:01<00:00,  1.29s/it]\n",
            "100%|██████████| 175/175 [03:54<00:00,  1.34s/it]\n",
            "100%|██████████| 196/196 [03:55<00:00,  1.20s/it]\n",
            "100%|██████████| 146/146 [03:14<00:00,  1.34s/it]\n",
            "100%|██████████| 157/157 [02:51<00:00,  1.09s/it]\n",
            "100%|██████████| 162/162 [04:02<00:00,  1.50s/it]\n",
            "100%|██████████| 238/238 [06:02<00:00,  1.52s/it]\n",
            "100%|██████████| 170/170 [03:59<00:00,  1.41s/it]\n",
            "100%|██████████| 147/147 [03:25<00:00,  1.40s/it]\n",
            "100%|██████████| 172/172 [03:20<00:00,  1.17s/it]\n",
            "100%|██████████| 161/161 [03:21<00:00,  1.25s/it]\n",
            "100%|██████████| 138/138 [03:34<00:00,  1.55s/it]\n",
            "100%|██████████| 142/142 [02:58<00:00,  1.26s/it]\n",
            "100%|██████████| 176/176 [04:16<00:00,  1.46s/it]\n",
            "100%|██████████| 185/185 [03:29<00:00,  1.13s/it]\n",
            "100%|██████████| 164/164 [03:39<00:00,  1.34s/it]\n",
            "100%|██████████| 177/177 [03:50<00:00,  1.30s/it]\n",
            "100%|██████████| 162/162 [03:37<00:00,  1.34s/it]\n",
            "100%|██████████| 178/178 [04:43<00:00,  1.59s/it]\n",
            "100%|██████████| 154/154 [03:10<00:00,  1.24s/it]\n",
            "100%|██████████| 169/169 [03:25<00:00,  1.21s/it]\n",
            "100%|██████████| 173/173 [04:16<00:00,  1.49s/it]\n",
            "100%|██████████| 167/167 [03:20<00:00,  1.20s/it]\n",
            "100%|██████████| 206/206 [04:20<00:00,  1.27s/it]\n",
            "100%|██████████| 183/183 [03:47<00:00,  1.24s/it]\n",
            "100%|██████████| 180/180 [04:07<00:00,  1.37s/it]\n",
            "100%|██████████| 190/190 [04:41<00:00,  1.48s/it]\n",
            "100%|██████████| 166/166 [03:21<00:00,  1.22s/it]\n",
            "100%|██████████| 171/171 [03:30<00:00,  1.23s/it]\n",
            "100%|██████████| 197/197 [04:26<00:00,  1.35s/it]\n",
            "100%|██████████| 174/174 [04:01<00:00,  1.39s/it]\n",
            "100%|██████████| 192/192 [04:02<00:00,  1.26s/it]\n",
            "100%|██████████| 203/203 [04:01<00:00,  1.19s/it]\n",
            "100%|██████████| 161/161 [03:17<00:00,  1.23s/it]\n",
            "100%|██████████| 148/148 [02:51<00:00,  1.16s/it]\n",
            "100%|██████████| 208/208 [04:16<00:00,  1.24s/it]\n",
            "100%|██████████| 190/190 [03:52<00:00,  1.23s/it]\n",
            "100%|██████████| 153/153 [03:24<00:00,  1.34s/it]\n",
            "100%|██████████| 234/234 [04:21<00:00,  1.12s/it]\n",
            "100%|██████████| 201/201 [03:44<00:00,  1.12s/it]\n",
            "100%|██████████| 157/157 [03:27<00:00,  1.32s/it]\n",
            "100%|██████████| 173/173 [03:30<00:00,  1.22s/it]\n",
            "100%|██████████| 146/146 [02:55<00:00,  1.20s/it]\n",
            "100%|██████████| 186/186 [03:51<00:00,  1.24s/it]\n",
            "100%|██████████| 158/158 [02:53<00:00,  1.10s/it]\n",
            "100%|██████████| 173/173 [03:02<00:00,  1.05s/it]\n",
            "100%|██████████| 163/163 [03:13<00:00,  1.19s/it]\n",
            "100%|██████████| 187/187 [04:14<00:00,  1.36s/it]\n",
            "100%|██████████| 164/164 [03:25<00:00,  1.25s/it]\n",
            "100%|██████████| 197/197 [04:08<00:00,  1.26s/it]\n",
            "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n",
            "100%|██████████| 164/164 [03:15<00:00,  1.19s/it]\n",
            "100%|██████████| 133/133 [02:52<00:00,  1.30s/it]\n",
            "100%|██████████| 206/206 [04:51<00:00,  1.42s/it]\n",
            "100%|██████████| 184/184 [04:33<00:00,  1.49s/it]\n",
            "100%|██████████| 155/155 [03:32<00:00,  1.37s/it]\n",
            "100%|██████████| 166/166 [03:01<00:00,  1.10s/it]\n",
            "100%|██████████| 205/205 [04:47<00:00,  1.40s/it]\n",
            "100%|██████████| 204/204 [04:07<00:00,  1.21s/it]\n",
            "100%|██████████| 197/197 [04:14<00:00,  1.29s/it]\n",
            "100%|██████████| 153/153 [04:30<00:00,  1.77s/it]\n",
            "100%|██████████| 199/199 [04:32<00:00,  1.37s/it]\n",
            "100%|██████████| 144/144 [05:42<00:00,  2.38s/it]\n",
            "100%|██████████| 174/174 [03:39<00:00,  1.26s/it]\n",
            "100%|██████████| 188/188 [05:35<00:00,  1.78s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dyKfp0CUcdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44fae4c-7201-450b-cfc9-57c1dfcb509c"
      },
      "source": [
        "# Create test dataset\n",
        "dataset_test_path= '/content/drive/Shareddrives/AI_Project/DatasetVietNam/DataVietNam/VietNam/VN_Male_Test' # Test data path\n",
        "test_x, test_y = load_dataset(dataset_test_path, embedder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:44<00:00,  1.49s/it]\n",
            "100%|██████████| 30/30 [00:38<00:00,  1.29s/it]\n",
            "100%|██████████| 30/30 [00:38<00:00,  1.28s/it]\n",
            "100%|██████████| 30/30 [00:43<00:00,  1.44s/it]\n",
            "100%|██████████| 30/30 [00:36<00:00,  1.21s/it]\n",
            "100%|██████████| 30/30 [00:46<00:00,  1.54s/it]\n",
            "100%|██████████| 30/30 [00:37<00:00,  1.24s/it]\n",
            "100%|██████████| 30/30 [00:38<00:00,  1.27s/it]\n",
            "100%|██████████| 30/30 [00:45<00:00,  1.52s/it]\n",
            "100%|██████████| 30/30 [00:43<00:00,  1.44s/it]\n",
            "100%|██████████| 30/30 [00:37<00:00,  1.25s/it]\n",
            "100%|██████████| 30/30 [01:09<00:00,  2.32s/it]\n",
            "100%|██████████| 30/30 [00:40<00:00,  1.37s/it]\n",
            "100%|██████████| 30/30 [00:49<00:00,  1.64s/it]\n",
            "100%|██████████| 30/30 [00:43<00:00,  1.47s/it]\n",
            "100%|██████████| 30/30 [00:44<00:00,  1.49s/it]\n",
            "100%|██████████| 30/30 [00:38<00:00,  1.27s/it]\n",
            "100%|██████████| 30/30 [00:58<00:00,  1.94s/it]\n",
            "100%|██████████| 30/30 [00:32<00:00,  1.08s/it]\n",
            "100%|██████████| 30/30 [00:28<00:00,  1.04it/s]\n",
            "100%|██████████| 30/30 [00:37<00:00,  1.26s/it]\n",
            "100%|██████████| 30/30 [00:38<00:00,  1.29s/it]\n",
            "100%|██████████| 30/30 [00:52<00:00,  1.73s/it]\n",
            "100%|██████████| 30/30 [00:52<00:00,  1.75s/it]\n",
            "100%|██████████| 30/30 [00:45<00:00,  1.51s/it]\n",
            "100%|██████████| 30/30 [00:53<00:00,  1.78s/it]\n",
            "100%|██████████| 30/30 [00:38<00:00,  1.28s/it]\n",
            "100%|██████████| 30/30 [01:05<00:00,  2.17s/it]\n",
            "100%|██████████| 30/30 [00:35<00:00,  1.20s/it]\n",
            "100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n",
            "100%|██████████| 30/30 [00:50<00:00,  1.69s/it]\n",
            "100%|██████████| 30/30 [00:53<00:00,  1.77s/it]\n",
            "100%|██████████| 30/30 [01:05<00:00,  2.19s/it]\n",
            "100%|██████████| 30/30 [00:42<00:00,  1.41s/it]\n",
            "100%|██████████| 30/30 [00:45<00:00,  1.52s/it]\n",
            "100%|██████████| 30/30 [00:36<00:00,  1.21s/it]\n",
            "100%|██████████| 30/30 [00:50<00:00,  1.67s/it]\n",
            "100%|██████████| 30/30 [00:41<00:00,  1.39s/it]\n",
            "100%|██████████| 30/30 [00:56<00:00,  1.89s/it]\n",
            "100%|██████████| 30/30 [00:34<00:00,  1.14s/it]\n",
            "100%|██████████| 30/30 [00:37<00:00,  1.23s/it]\n",
            "100%|██████████| 30/30 [00:55<00:00,  1.86s/it]\n",
            "100%|██████████| 30/30 [00:45<00:00,  1.51s/it]\n",
            "100%|██████████| 30/30 [00:46<00:00,  1.54s/it]\n",
            "100%|██████████| 30/30 [00:34<00:00,  1.14s/it]\n",
            "100%|██████████| 30/30 [00:34<00:00,  1.14s/it]\n",
            "100%|██████████| 30/30 [00:44<00:00,  1.47s/it]\n",
            "100%|██████████| 30/30 [00:42<00:00,  1.40s/it]\n",
            "100%|██████████| 30/30 [00:44<00:00,  1.49s/it]\n",
            "100%|██████████| 30/30 [00:41<00:00,  1.40s/it]\n",
            "100%|██████████| 30/30 [00:50<00:00,  1.70s/it]\n",
            "100%|██████████| 30/30 [00:42<00:00,  1.40s/it]\n",
            "100%|██████████| 30/30 [00:58<00:00,  1.95s/it]\n",
            "100%|██████████| 30/30 [00:40<00:00,  1.34s/it]\n",
            "100%|██████████| 30/30 [00:40<00:00,  1.34s/it]\n",
            "100%|██████████| 30/30 [00:39<00:00,  1.32s/it]\n",
            "100%|██████████| 30/30 [00:44<00:00,  1.49s/it]\n",
            "100%|██████████| 30/30 [00:38<00:00,  1.27s/it]\n",
            "100%|██████████| 30/30 [00:35<00:00,  1.20s/it]\n",
            "100%|██████████| 30/30 [00:42<00:00,  1.41s/it]\n",
            "100%|██████████| 30/30 [00:40<00:00,  1.35s/it]\n",
            "100%|██████████| 30/30 [00:37<00:00,  1.26s/it]\n",
            "100%|██████████| 30/30 [00:39<00:00,  1.31s/it]\n",
            "100%|██████████| 30/30 [00:40<00:00,  1.37s/it]\n",
            "100%|██████████| 30/30 [00:37<00:00,  1.24s/it]\n",
            "100%|██████████| 30/30 [00:47<00:00,  1.57s/it]\n",
            "100%|██████████| 30/30 [00:42<00:00,  1.41s/it]\n",
            "100%|██████████| 30/30 [00:34<00:00,  1.15s/it]\n",
            "100%|██████████| 30/30 [00:37<00:00,  1.26s/it]\n",
            "100%|██████████| 30/30 [00:36<00:00,  1.22s/it]\n",
            "100%|██████████| 30/30 [00:36<00:00,  1.22s/it]\n",
            "100%|██████████| 30/30 [00:36<00:00,  1.21s/it]\n",
            "100%|██████████| 30/30 [00:41<00:00,  1.37s/it]\n",
            "100%|██████████| 30/30 [00:36<00:00,  1.20s/it]\n",
            "100%|██████████| 30/30 [00:27<00:00,  1.08it/s]\n",
            "100%|██████████| 30/30 [00:41<00:00,  1.38s/it]\n",
            "100%|██████████| 30/30 [00:36<00:00,  1.20s/it]\n",
            "100%|██████████| 30/30 [00:39<00:00,  1.33s/it]\n",
            "100%|██████████| 30/30 [00:39<00:00,  1.30s/it]\n",
            "100%|██████████| 30/30 [00:33<00:00,  1.10s/it]\n",
            "100%|██████████| 30/30 [00:33<00:00,  1.10s/it]\n",
            "100%|██████████| 30/30 [00:35<00:00,  1.19s/it]\n",
            "100%|██████████| 30/30 [00:41<00:00,  1.38s/it]\n",
            "100%|██████████| 30/30 [00:36<00:00,  1.21s/it]\n",
            " 47%|████▋     | 14/30 [00:14<00:16,  1.00s/it]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB_kEPEUMwzx"
      },
      "source": [
        "## Training model classification using SVM method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1CNztoVrdkU"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# label encode targets\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(train_y)\n",
        "train_y = out_encoder.transform(train_y)\n",
        "test_y = out_encoder.transform(test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku2Pc34proVt"
      },
      "source": [
        "# tranning model\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(train_x, train_y)\n",
        "# score\n",
        "score_train = model.score(train_x, train_y)\n",
        "score_test = model.score(test_x, test_y)\n",
        "# summarize\n",
        "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz7R2a4NNSZQ"
      },
      "source": [
        "## Use model to recognize faces in images (test for show image and probrability)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-DGVe3K1H0k"
      },
      "source": [
        "# Get predict of image\n",
        "import cv2\n",
        "# read image from file path\n",
        "image = cv2.imread('') # Image test path\n",
        "# convert to RGB, if needed\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "# convert to array\n",
        "pixels = asarray(image)\n",
        "# create the detector, using default weights\n",
        "detections = embedder.extract(pixels)\n",
        "# loop through each face in detections\n",
        "for detect in detections:\n",
        "    # get embedded image\n",
        "    embedded_img = detect['embedding']\n",
        "\n",
        "    # expand dimension for feeding data to the model\n",
        "    samples = np.expand_dims(embedded_img, axis=0)\n",
        "\n",
        "    # get predict from model\n",
        "    yhat_class = model.predict(samples)\n",
        "    yhat_prob = model.predict_proba(samples)\n",
        "\n",
        "    # get label name\n",
        "    class_index = yhat_class[0]\n",
        "    predict_names = out_encoder.inverse_transform(yhat_class)[0]\n",
        "\n",
        "    # get probability\n",
        "    class_probability = round(yhat_prob[0,class_index] * 100)\n",
        "    print('Predict image has person: ', predict_names, ' with confidence:', class_probability)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6agvYnm1SqM"
      },
      "source": [
        "# OUTPUT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em0s-4VS_pqY"
      },
      "source": [
        "input_loc = '/content/gdrive/MyDrive/data/xxxxx.mp4'\n",
        "output_loc = '/content/gdrive/MyDrive/data/'\n",
        "my_file = open(output_loc + 'list_faces.txt','a+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb1BFH7UxCpC"
      },
      "source": [
        "def detect_face(image,frame_number,fps):\n",
        "  # convert to array\n",
        "  pixels = asarray(image)\n",
        "  # create the detector, using default weights\n",
        "  detections = embedder.extract(pixels)\n",
        "  # loop through each face in detections\n",
        "  for detect in detections:\n",
        "    # get embedded image\n",
        "    embedded_img = detect['embedding']\n",
        "    # get coordinates (x,y) and weight, height (w, h) of the bounding box\n",
        "    x,y,w,h = detect['box']\n",
        "    \n",
        "    # expand dimension for feeding data to the model\n",
        "    samples = np.expand_dims(embedded_img, axis=0)\n",
        "\n",
        "    # get predict from model\n",
        "    yhat_class = model.predict(samples)\n",
        "    yhat_prob = model.predict_proba(samples)\n",
        "\n",
        "    # get label name\n",
        "    class_index = yhat_class[0]\n",
        "    predict_names = out_encoder.inverse_transform(yhat_class)[0]\n",
        "\n",
        "    # get probability\n",
        "    class_probability = round(yhat_prob[0,class_index] * 100)\n",
        "    \n",
        "    # Put label name if probability >50% and 'Unknown'' if <= 50%\n",
        "    if class_probability > 50:\n",
        "      # Vẽ một hình tứ giác xung quanh các khuôn mặt phát hiện được. Vẽ trên ảnh màu.\n",
        "      cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "      cv2.putText(image, \"{}:{:.0f}%\".format(predict_names,class_probability), \n",
        "                  (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)\n",
        "      # Hiển thị kết quả ra màn hình\n",
        "      cv2_imshow('Face Detection', image)\n",
        "      #time    \n",
        "      duration= frame_number/fps\n",
        "      minutes = int(duration/60)\n",
        "      seconds = duration%60\n",
        "\n",
        "      #write out\n",
        "      my_file.write('Time('+ str(minutes) + ':' + str(seconds) + '),' \n",
        "                    + \"{}:{:.0f}%\".format(predict_names,class_probability)\n",
        "      cv2.imwrite(output_loc + \"frame/%#05d.jpg\" % (frame_number), image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9vtNcuh6-bP"
      },
      "source": [
        "import cv2\n",
        "cap = cv2.VideoCapture(input_loc)\n",
        "video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)  \n",
        "while cap.isOpened():\n",
        "  # do stuff\n",
        "  frame_number += 5\n",
        "  if (frame_number > (video_length-1)):\n",
        "    # Release the feed\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    break\n",
        "\n",
        "  cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
        "  # Extract the frame\n",
        "  ret, frame = cap.read()\n",
        "  # convert to RGB, if needed\n",
        "  image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "  # Thực thi Face Detection\n",
        "  detect_face(image,frame_number,fps)\n",
        "  \n",
        "my_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}